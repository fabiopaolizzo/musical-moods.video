# MUSICAL-MOODS: Video Data

This repository contains the video data component of the MUSICAL-MOODS project, a foundational resource for training and validating AI models on complex, subjective, and unstructured human data.

**For a full overview of the project, please see the [central project hub](https://github.com/fabiopaolizzo/musical-moods.main).**

---

### Data Description

The data in this repository consists of **complete, continuous video recordings** of the full dance improvisation sessions (640x360 resolution). The video was captured from a fixed, wide-angle perspective to serve two primary purposes:

1.  It provides a rich source for **computer vision analysis** of the dancer's movements and overall performance context.
2.  Critically, it serves as the **qualitative ground truth and validation reference** for the corresponding high-dimensional motion capture (MoCap) data.

### Potential Applications & Research Areas

This dataset is a rich resource for research in computer vision and behavioral analysis. It is particularly well-suited for developing and benchmarking models in:

-   **Computer Vision:** Applying algorithms to real-world, complex human movement.
-   **Human Pose Estimation:** Tracking and analyzing the kinematics of the human form.
-   **Behavioral Analysis:** Correlating visual cues with other data modalities (e.g., language, MoCap) to understand behavior.

---

*This research was supported by the EU's Horizon 2020 programme (MSCA-IF-GF, REA Grant Agreement No. 659434).*
